# How Druid enables analytics at Airbnb

source: https://medium.com/airbnb-engineering/druid-airbnb-data-platform-601c312f2a4c

Airbnb의 데이터 플랫폼 팀은 엄청난 양의 데이터를 수집, 구성 및 처리하는 인프라를 제공하고 다양한 조직에서 요구하는 분석을 가능케하여 데이터에 기반한 의사결정을 내릴 수 있도록 하는 것이다.

고수준의 분석이 공유되는 주된 방법은 다양한 `대시보드`를 활용하는 것이다. 대시보드는 비즈니스의 여러가지 측면에 대해 실시간 트래킹와 모니터링을 제공하므로, 적시의 대시보드 제공은 필수적이다.

이를 위해 데이터 플랫폼 팀은 3개의 과제를 수행하게된다.

1. DW로부터 데이터를 집계하고 쿼리시 Hive, Presto를 활용하여 대시보드에 필요한 데이터를 생성하는데 시간이 오래 걸린다.
2. 시스템이 안정적이며 스케일러블 해야한다.
3. 오픈소스 프레임워크 기반의 데이터 인프라와 통합이 가능해야한다.
  - Airbnb의 데이터는 `Hadoop`에 저장되며 `Kafka`, `Spark streaming` 등의 스트림 처리와 통합하는것이 필요하다.

## Druid의 장점

**1. 빠른 쿼리 시간**

미리 정의된 데이터 소스와 전처리된 집계로 Druid는 굉장히 낮은 지연시간을 보인다. 그렇기에 Druid를 기반으로 하는 대시보드는 다른 시스템에 비해 눈에 띄게 빠르다. `Hive`, `Presto`와 비교했을 때 Druid는 훨씬 더 빠를 수 있다.

**2. 안정성과 확장가능성을 고려한 구조**

Druid의 아키텍처는 추출, 서빙, 조정을 위한 컴포넌트가 모두 분리되어있기 때문에 안정적이고 확장이 가능하다고 판단했다. 또한 데이터 스토리지를 저장 기간에 따라 나누는 구조를 가진다. S3에 분석용 데이터를 저장하여 disaster recovery를 대비하고 쉽게 업그레이드 및 유지보수를 할 수 있다.

**3. 오픈소스 프레임워크와 통합**

Druid는 Hadoop, Kafka와 같은 오픈소스 데이터 인프라와 긴밀히 연결된다. Druid의 API는 Hadoop에서 배치 분석을 위한 기능을 제공하며 JVM기반 스트리밍 엔진과 통합할 수 있는 클라이언트 API인 `Tranquility`를 제공하여 실시간 분석 또한 지원한다. 마지막으로 `Apache Superset`(데이터 시각화 도구)와 통합이 쉽다.

## Airbnb에서 어떻게 Druid를 사용하는지: 듀얼 클러스터 설정

Airbnb에서는 2개의 Druid 클러스터를 다른 목적으로 운영하고 있으며, 그 중 하나는 중앙 집중 메트릭 서비스를 위해 사용하고 있다. 이는 Airbnb의 모든 대시보드를 제공하고, 사용자는 간단한 YAML파일로 메트릭을 정의할 수 있다. 사용자는 Druid의 지식 없이도 Superset의 메트릭과 대시보드를 제공받을 수 있다.

모든 배치 작업들은 Airflow로 스케줄링되고있고, HDFS 클러스터로부터 데이터를 추출하여 처리한다.

모든 실시간과 다른 데이터 소스들은 다른 Druid 클러스터로 운영된다. 실시간 데이터는 `Spark Streaming`과 `Tranquility` 클라이언트 세팅으로 운영하고 있다.

## Airbnb에서 Druid를 사용하여 고도화하기

Druid는 강력하고 많은 기능들을 제공하지만 Druid의 위에서 특별한 유즈케이스를 구현하기 위해 고도화하였다.

**1. 애드혹 쿼리에 즉시 응답이 가능한 프레임워크**

수많은 데이터 분석가들의 애드혹 쿼리를 수행할 수 있도록 Druid의 위에서 자체 서비스를 구현하여 적용했다. config 파일을 통해 data source를 정의하면 실시간과 배치 데이터에 관계없이 데이터를 가져올 수 있다.

Druid를 통해 빠르게 집계된 실시간 데이터의 추출으로 이상 감지를 하고있다. 신속하게 수집 및 집계된 실시간 데이터를 통해 예상 패턴과 일치하지 않는 프로덕션 환경을 매우 빠르게 감지하고 있다.

**2. Presto와 통합**

Druid는 HTTP RESTful API를 활용한 JSON 쿼리 매커니즘이 성숙하고, 최신 버전의 SQL 쿼리 지원이 가능지만 다른 데이터 소스와의 Join 연산(cross join)이 불가능하다. 즉 모든 집계 연산은 싱글 데이터 소스로 제한된다. Airbnb에서는 다양한 데이터 소스, 다양한 차원의 데이터의 cross join이 필요한 시나리오가 존재한다. 개별 데이터 솟별로 쿼리를 Druid로 push하고 데이터를 검색 및 결합하여 데이터 소스간 쿼리 실행을 완료할 수 있는 `Presto connector`를 도입했다. 이는 Druid에게 각 데이터 소스에 대한 질의를 위임(query push-down) 할 수 있게 했고 cross join을 가능하게 만들었다.

**3. Backfill performance 향상**

Druid가 다른 시스템보다 빠른 이유는 데이터 추출 단계에서 존재한다. 모든 데이터는 쿼리를 할 수 있도록 MR 추출되는 과정이 필요하다. 이는 **write-once-read-multiple-times** 모델에 잘 동작하고 프레임워크는 매일 새로운 데이터를 수집하기만 하면 된다.

문제는 데이터 소스에서 데이터 형태를 바꾸거나 예전 데이터를 새로 만들때이다. 이는 수 년간 쌓인 데이터를 새로 추출하여 Druid의 예전 데이터를 새 데이터로 교체하는 것을 말한다. 이는 MR을 포함하는 매우 큰 추출 작업이며, 특히 중간에 작업이 중단될 경우 막대한 비용이 든다.

해결방법은 큰 추출 과정을 여러 개의 요청으로 나누어 저장하는 것이다. 하지만 예전 데이터와 새롭게 추출된 데이터가 섞인 쿼리는 데이터의 일관성이 없다. Backfill(예전 데이터를 넣어주는 작업)은 사용자 요구사항 및 수집 프레임워크 기능의 발전에 따라 생각보다 자주 일어나기 때문에 성능이 개선을 요구하는 골칫거리가 된다.

결국 Airbnb는 **새롭게 추출되는 segment를 활성화하기 전까지 inactive 상태를 유지**하도록 했다. 이는 추출 프레임워크를 데이터 소스와 허용 가능한 크기의 더 작은 주기로 분리할 수 있게 한다. 프레임워크는 이러한 주기로 추출을 병렬로 진행하며, 새로 추출된 데이터가 inactive이기 때문에 backfill 추출이 아직 진행중인 동안 실행중인 쿼리에 대한 결과를 계산할 때 다른 버전의 segment가 섞이지 않는다. 최신 데이터 소스를 위한 segment를 활성화하면 새로운 버전으로 downtime없이 refresh된다. Split와 refresh가 backfill의 성능을 크게 향상시켰고 하루보다 더 길었던 backfill을 1시간 내로 끝낼 수 있게 되었다.

**4. 모니터링과 운영**

Druid 자체적으로 견고한 설계를 가지고 있어 node failure에 대해 복구가 쉽다. 심지어 SPOF(coordinator, overload, zookeeper 등)의 fail에도 Druid 클러스터는 사용자에게 쿼리 결과를 제공할 수 있다. 하지만 SLA를 제공하려면 모든 서비스 중단을 제때 또는 오류가 발생하기 전에 포착해야 한다.

다른 클러스터들처럼 Druid의 상태를 알림을 통해 모니터링 하고있다. 모든 클러스터의 가용성을 모니터링하기 위해, 카나리아 데이터 추출 상태를 30분마다 체크하고, 각 broker node의 쿼리 결과가 추출된 데이터와 일치하는지 5분마다 확인한다. 

Druid는 Airbnb에서 다년간 운영해왔지만 가장 낮은 운영비를 가진다. 클러스터 관리자는 모니터링 메트릭을 확인하고 노드를 스케일링하고, Druid 클러스터의 데이터가 커짐에 따라 예전 노드 용량을 캐싱을 위해 추가하고 큰 데이터를 쉽게 서빙할 수 있다. 
